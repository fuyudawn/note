[TOC]

# 人工智能吴恩达学习记录
## 1

### What's machine learning?

机器学习：计算机程序从经验E进行学习，以解决某一任务T，并通过性能指数P来衡量效果。

现有的算法最主要的有有监督算法（我们教计算机）和无监督算法（计算机自学），其他的就是强化学习和推荐系统.

### supervised learning

有监督学习：给定一个带有正确答案的数据集，算法的目的就是给出更多正确答案。

回归问题：给出连续值输出

分类问题：给出离散值输出

### unsupervised learning

无监督学习：给定一个没有标签的数据集，算法的目的是找到其中不同的结构（簇）。
## 2

### 模型概述

m表示训练集的数量，x表示输入变量，y表示输出变量，(x,y)表示一个训练样本

在有监督学习中，输入一个训练集，输出一个函数，先决定如何表示这个假设函数

### 代价函数

在线性回归中，我们要解决一个最小化问题，使((h<font size=2>θ</font>(x)-y)^2)/2M最小。((h<font size=2>θ</font>(x)-y)^2)/2M就是这里的代价函数。这里的代价函数有时也被称为平方误差函数，这个函数适用于许多问题，尤其是回归问题（最常用）。

我们希望的是能够找到一种高效的算法，它可以自动计算代价函数的最小值以及对应的假设函数里的参数。

### 梯度下降

梯度下降法：将任意函数最小化

思路：先给定目标函数中变量的初始值（随意），之后不停地一点点改变参数的值使目标函数的函数值变小，直到我们找到目标函数的最小值或局部最小值。不同的初始值设定可能会导致最终得到不同的局部最小值。

![image-20220304193742292](C:\Users\沙洲\AppData\Roaming\Typora\typora-user-images\image-20220304193742292.png)

:=表示赋值，α在这里被称为学习率，用于控制梯度下降时我们迈出多大的步子。θ0和θ1要同时更新。导数项的符号决定你往哪个方向走，两个偏导数的比值值决定你走的具体方向，α决定你一个步子迈多大。选取合适的α很重要，过小的α会使速率过低，过高的α则可能导致无法收敛/发散。

batch:全览整个数据集
## 4

### 多功能

像h<font size=2>θ</font>(x)=θ0+θ1\*x1+θ2\*x2+θ3\*x3+θ4\*x4这样的函数表达式，可以用矩阵来分解。假如说A=[θ0,θ1,θ2,θ3,θ4]，B=[1,x1,x2,x3,x4,x5]那么表达式就可以写成A*B<font size=2>T</font>。这是常用的分解技巧。

### 多元梯度下降法

![image-20220305192130697](C:\Users\沙洲\AppData\Roaming\Typora\typora-user-images\image-20220305192130697.png)

其实和前面差不多，变量多了多求几个偏导罢了

### 特征缩放

确保所有特征的尺度相似，否则梯度下降的时间会比较长，如图

![image-20220305221644782](C:\Users\沙洲\AppData\Roaming\Typora\typora-user-images\image-20220305221644782.png)

如果尺度相似，等高线就会更接近圆，就能得到一条更直接的路径到达最小值

有时人们也会把特征先中心化（减去均值）然后再缩放。因此，所要做的操作就是将特征减去平均值，然后再除以缩放系数，缩放系数可以是极差，也可以是标准差。

### 学习率α

可以设定一个ε，当迭代以后代价函数的值的变化小于这个数时，就停止迭代，但是这个值的选取是比较困难的。或者也可以直接看迭代次数与代价函数最小值的关系曲线图来确定迭代多少次以后算已经收敛，这个图也可以看出α是否合适。

学习率可以按3的倍数一个个取，最终找到合适的值。

### 特征与多项式回归

有时可以创造新的特征来得到更好的假设函数。

对于多项式线性回归，比如你要拟合一个二次函数y=k0+k1\*x1+k2\*x1^2，只需要把x1^2的那一项用一个新特征x2=x1^2代替就行了，这样我们就把多项式拟合转换回了线性回归。而且在这种情况，缩放变得更加重要，缩放可以使得x和x^2的尺度都差不多。

### 正规方程（区别于迭代的直接解法）

1、对训练样本的特征（输入）（加上第一列为[1]）构建矩阵X，一列代表一个特征，一行代表一个样本，对训练样本的输出构建向量y。能使代价函数最小的θ就等于向量(XTX)^-1\*XT*y，用这个方法也不需要特征变量了。这个方法的缺点就是如果维度很大的话运行起来会相当地慢，其他都是优点。

2、如果XTX不可逆，我们首先要看看这个矩阵里是否有多余的特征（线性相关的），如果是特征过多的话可以删除一些不太重要的特征，或者正规化（regularization）。
## 6
### 分类

沿袭：继续沿用线性回归的方法，对样本拟合一条直线，当输出值大于阈值时，样本分类为1，否则为0（不过这并不是一个好方法，因为拟合线性函数太生硬，导致容易被训练样本戏耍）

### 假设陈述

logistic regression分类算法：使假设函数的输出范围一直处于0和1之间。g(z)是一个sigmoid函数。

![image-20220306160111490](C:\Users\沙洲\AppData\Roaming\Typora\typora-user-images\image-20220306160111490.png)

区别仅仅是换了一个函数表示，代价函数还是那样，我们还是通过和之前一样的办法来求解合适的θ。现在假设函数输出的意义就是当x为这个值时，y=1的概率是多少。

### 决策界限

通过g(z)函数的形式我们可以发现，g(z)>0.5的条件就是z>0，因此，就是说θTx>=0即有g(z)>0.5。

决策边界就是不同类别的分界线，在分界线不同侧的区域的点被标为不同的类别。

### logistic回归模型的代价函数

如果继续沿用之前的那个平方误差函数作为代价函数，会导致这个函数变为非凸函数，会有不少局部最小值干扰梯度下降法的使用。![image-20220308234223680](C:\Users\沙洲\AppData\Roaming\Typora\typora-user-images\image-20220308234223680.png)

![image-20220308234815955](C:\Users\沙洲\AppData\Roaming\Typora\typora-user-images\image-20220308234815955.png)

这个函数（指单个样本的代价）就能满足我们的需求，是一个凸函数。![image-20220309000409476](C:\Users\沙洲\AppData\Roaming\Typora\typora-user-images\image-20220309000409476.png)

把两个式子写在一起就成这样了![image-20220309000637318](C:\Users\沙洲\AppData\Roaming\Typora\typora-user-images\image-20220309000637318.png)

![image-20220309001144468](C:\Users\沙洲\AppData\Roaming\Typora\typora-user-images\image-20220309001144468.png)

梯度下降法更新

### 高级优化

使用比梯度下降更高级的算法来最小化代价函数，如共轭梯度，BFGS，L-BFGS。优点是不需要自动选择学习率α，速度更快，但是模型本身也比梯度下降更复杂。

### 多元分类

将多元分类转化为多个独立的两两分类的问题。对于每个两两分类问题，我们都能获得一个假设函数。把我们要预测的点放到那些函数上，看看每个类的概率多少，挑概率最高的类别即可。

## 7

### 过拟合

在变量过多时出现，虽然代价函数的值很小，但是过于追求符合每一个数据，导致泛用性很差。

解决方法：绘制假设模型的曲线图观察是否过拟合，如果是的话则重新选择模型。

一般来说，过拟合的原因就是变量太多，我们需要减少使用的变量，选用更为重要的变量。或者进行正则化。

### 正则化

通过改变代价函数，加上一些项![image-20220309204108694](C:\Users\沙洲\AppData\Roaming\Typora\typora-user-images\image-20220309204108694.png)

这样子的话，就可以缩小参数（不必加上θ0，这是约定俗成的），使曲线更平滑，最右边的那个就是正则化项，其中的参数就是正则化参数。正则化项使模型更简单，曲线更平滑。正则化参数也不能太大，不然就全变成0了。后面的梯度下降的方法和之前的是一样的，只是因为代价函数多了一项导致偏导数也变了而已。![image-20220309225914329](C:\Users\沙洲\AppData\Roaming\Typora\typora-user-images\image-20220309225914329.png)

这就是正规方程正则化后的公式，由代价函数的导数求得。只要λ>0，可以保证矩阵可逆。（矩阵一列一个特征，一行一个样本）![image-20220309231244041](C:\Users\沙洲\AppData\Roaming\Typora\typora-user-images\image-20220309231244041.png)

对于logstic方法，正则项也是一样的。

## 8

### 非线性降维

如果特征数量过多的话，将高阶特征包含到假设函数中时，特征数量会急速膨胀，导致过拟合。因此通过这样增加特征来建立非线性分类器并不是一种好方法。

### 神经网络

目的：模仿大脑

用一个算法处理多种东西

### 模型展示

我们把神经元模拟为一个逻辑单元

![image-20220310210515365](C:\Users\沙洲\AppData\Roaming\Typora\typora-user-images\image-20220310210515365.png)

黄色的圈圈类似于神经元细胞体，通过树突或输入通道给神经元细胞体传递信息，然后神经元做一些计算，通过其输出通道输出计算结果。

激活函数是指代非线性函数的g(z)的另一个术语。一个节点的**激活函数**定义了该节点在给定的输入或输入的集合下的输出，只有非线性激活函数才允许这种网络仅使用少量节点来计算非平凡问题，也被称为传递函数。我们之前说的参数θ在此被称为模型的权重。

![image-20220310211039516](C:\Users\沙洲\AppData\Roaming\Typora\typora-user-images\image-20220310211039516.png)

神经网络就是一组神经元连接在一起的集合。第一层也被称为输入层，最后一层也被称为输出层，中间那一层被称为隐藏层，因为这一层的值我们是看不见的，其既不是输入也不是输出。神经网络可以有不止一个隐藏层，任何非输出层和输入层都是隐藏层。激活项就是神经网络计算并输出的值。a(2)_1就表示第二层第一个单元的激活项。神经网络被矩阵参数化，权重矩阵控制着从某一层到下一层的映射。权重矩阵的维度就是（第j+1层的神经元个数*第j层的神经元个数+1），因为输入里面还有偏置项的存在比如a0，x0。因此改变θ我们就能获得不同的假设，不同的函数。

![image-20220310222506818](C:\Users\沙洲\AppData\Roaming\Typora\typora-user-images\image-20220310222506818.png)

将矩阵运算向量化，z指的是输入神经网络的加权线性组合，可以看到右边的式子写出了如何向量化地进行运算。这张图描述的计算方式就是前向传播。

![image-20220310223433093](C:\Users\沙洲\AppData\Roaming\Typora\typora-user-images\image-20220310223433093.png)

把前面盖住，这里就像是之前说的logstic模型，但是我们这里使用的特征是通过隐藏层计算的数值，是网络自己训练出来的东西，计算出一些较为复杂的特征。根据θ1的不同，我们就可以训练出不同的特征。不同的权重可以使网络学习到具有不同功能的模型。隐藏层越多，计算的函数（特征）就越复杂。

### 多元分类

这样我们就需要建立具有多个输出单元的神经网络，输出含多个数的向量，每个数用于判断该东西是否为某一类东西。类似于之前的一对多法。对于训练集也要改一下，输入仍然不变，但是对应的输出要改为[0, 1, 0, 0...]之类的形式，以使得训练出来的函数约等于正确结果。

![image-20220311215419384](C:\Users\沙洲\AppData\Roaming\Typora\typora-user-images\image-20220311215419384.png)

在多元分类中，我们修改了代价函数，使得每个项的偏差都被考虑了进去，正则项也计算了每一个权重矩阵的项元素的平方，以适应新的情景。

## 9

### 反向传播算法

对于多元分类，我们继续延续使用梯度下降的方法。我们定义损失函数L(θ)为每个输出和样本中对应的输出值的距离的和，至于这个距离具体用的是什么距离，都可以，看你自己的选择。为了通过原来的方法去进行梯度下降，我们需要计算L(θ)对所有θ的导数。如果直接对L(θ)求导数的话，由于神经网络对特征进行了多重变换，特征非常多，计算偏导数效率低下。这时候，为了使得计算导数更有效率，我们所采用的就是反向传播算法。

推导所使用的数学知识：导数的运算，仅仅如此。推断详见：https://www.youtube.com/watch?v=ibJpTrp5mcE&list=PLJV_el3uVTsPy9oCRY30oBPNLCo89yu49&index=12&t=435s

具体使用：先正向传播计算出每个激活项和输出项的值，然后反向传播计算损失函数对每个参数的偏导数。

### 梯度检验

有时候反向传播会出bug，导致误差很高（往往与反向传播的错误实现有关），所以需要进行梯度检验。

梯度估计：取离这个点非常相近的前后两个点，将这两个点连起来，直线的斜率就近似于该点的梯度。但是也不能太近，不然会引发一些数值问题，因此一般设为前后10^-4。理论上通过这种方法计算出来的导数和反向传播计算出来的导数是差不多的，如果是这样的话，那么就没问题。

![image-20220312164309357](C:\Users\沙洲\AppData\Roaming\Typora\typora-user-images\image-20220312164309357.png)

### 随机初始化

一开始不能全部设置为0，否则会导致每次更新的时候参数都还是一样的。

用随机初始化来初始化就可以了，在-a到a之间随机取一个数作为参数。

### 神经网络小结

1、决定神经元架构，一般来说只有一个隐藏层，如果有多个隐藏层那么一般来说每个隐藏层单元数应该是一样的。通常来说隐藏层的单元越多越好，但是隐藏层越多计算量越大，而且隐藏层的数量应该和输入的X的维度（特征的数目）相匹配才好，可以是特征数目的1、2、3、4倍。

2、随机初始化参数。

3、前向传播计算出对应的每个激活项和输出项的值。

4、计算出代价函数，并通过反向传播来计算代价函数对每个参数的偏导数。

5、用梯度检查估算的导数查看反向传播有没有问题。

6、最后使用最优化方法比如梯度下降或者更高级的优化方法。

## 10

### 决定下一步做什么

有机器学习诊断法，通过这种方法我们可以了解算法的哪里出了问题以及如何改进，花费的时间较长。

### 评估假设

对于过拟合，如果是简单的例子，可以直接画出假设函数，对于复杂的例子，我们可以将原始数据随机分为两部分，一份作为训练集，一份作为测试集。计算模型应用于测试集的精度或者用测试集的数据计算代价函数的值。

### 模型选择

用同一数据集作为测试集计算出的误差并不一定能很好地展示泛化误差。因为根据测试集选出来的模型肯定是适合测试集的，但是不代表它就一定适合其他的数据。

为了解决这个问题，可以考虑将原始样本分为三份，训练集：交叉验证集：测试集=6：2：2（经典分配）。我们可以用模型在交叉验证集上的误差来筛选用训练集训练后的模型，选出来后，用测试集来衡量这个模型的泛化误差。

### 区分欠拟合和过拟合

![image-20220313215310467](C:\Users\沙洲\AppData\Roaming\Typora\typora-user-images\image-20220313215310467.png)

紫线指的是假设函数的次数和模型应用在训练集上的误差的关系；红线指的是假设函数的次数和模型应用在交叉验证集集上的误差的关系。如果二者都很高，说明模型有欠拟合的问题，如果应用在训练集的误差远小于交叉验证集的误差，说明模型有过拟合的问题。

### 正则化

如果正则化参数过大，则最后参数都很接近0，导致欠拟合；如果正则化参数过小，则仍会出现过拟合的问题。

对于测试集验证模型用的代价函数，我们并不会加上正则项，对于交叉训练集也一样。可以选取多个正则化参数（通常取2的k次方），训练多个模型，得到不同的参数，方法就跟之前选取模型一样，先在交叉验证集里面看看，然后用测试集观察模型的泛化能力。

### 学习曲线

首先绘制出训练集和交叉验证集的平方误差函数和样本数的关系曲线图。可以猜想得到，随着训练集样本数的增加，训练集平方误差函数的值会变大，因为假设函数会越来越难覆盖所有训练集的样本；而交叉验证集平方误差函数的值则会变小，因为随着样本数的增多模型的泛化能力会越来越强。

如果最后随着样本数的增加模型对于训练集和交叉验证集的偏差都仍然很大（相近）且没有下降趋势的话，说明我们的预设的模型有高偏差的问题（欠拟合，特征过少）。如果最后随着样本数的增加模型对于训练集的偏差仍较小，但是对交叉验证集偏差仍然很大的话，说明模型出现了过拟合（方差过大）的问题。过拟合的话要么疯狂加样本数，不行的话就只能改模型了。

### 改进

罗列一下几个可以改进的方向：

增加样本数：高方差

减少特征数：高方差

增加特征数：高偏差

增加多项式特征：高偏差

降低正则化参数：高偏差

增加正则化参数：高方差

比较简单的神经网络，参数就会比较少，容易出现欠拟合，但优点是计算量也较小；比较复杂的神经网络（隐藏层多，隐藏层单元数多），参数就会比较多，较容易出现过拟合（不过可以用正则化解决），计算量也较大。使用复杂的神经网络并通过正则化去改善其过拟合现象常比较简单的神经网络所表现出来的效果更好。隐藏层一般一个就够了，当然也可以弄多几层，然后看看他们在交叉验证集中的表现来进行选择。

## 11

### 误差分析

一般都是先简单粗暴做一个东西出来再慢慢改进，而不是一开始就绞尽脑汁去做一个很复杂的东西出来。然后通过学习曲线看看模型是否有高方差或者高偏差的问题，来决定你要如何去改进它。之后进行误差分析，看看那些被错误分类的邮件是否有共同的特征，以此来启发如何设计新特征。评价指标可以使用交叉验证错误率。

### 不对称分类的误差评估

不对称的含义：分类的数量不对称，比如在数据集中A(T)类占了99.5%，而B(F)类只有0.5%。如果我们的模型在训练集中错误率只有1%，那么在那些相对对称的数据集中，这个结果是不错的；但如果是在这种不对称分类的数据集中，就显得不是那么好了，意味着你虽然TP、FP率不错，但是TN率和FN率很差（因为B类太少了，1%对其的影响很大）。

因此在判断预测这种偏斜类的模型时，我们需要将改进判断标准，引入TP、FP、TN、FN来更精确地判断模型的好坏。除此之外，还有两个东西：

Precision: 判断为阳性的人中有多少是真正阳性的--TP/(TP+FP)

Recall: 对于那些阳性的人，我们真正找到了多少--TP/(TP+FN)

如果这两个率都很高，那么说明这个算法即使是对于偏斜类，效果也是很好的。在分类时，阳性那一方一般是比较少的那一类。

### 精确度与召回率的平衡

有些时候，我们并不只是单纯地追求精确度，也要考虑一些其他的因素。比如如果阳性对应癌症，这是比较吓人的，我们希望尽可能精确一些，这样的话，我们可以提高判断标准。原先，我们认为假设函数>=0.5就判断为阳性，现在我们认为假设函数>=0.6才算阳性。这样的话，FP就会减少，查准率就会变高，但是召回率就会变小，因为我们判断标准的提高会导致更少的人被判断为有癌症。反之亦然，如果我们想要尽可能地不遗漏真正患有癌症的病人，那么我们就可以将判断标准调低，这样的话虽然查准率变低，但是召回率就会得到提高。

那么如果不同的模型得到了不同的查准率和召回率，如何判断哪个模型更好呢？我们可以使用F值，公式为2PR/(P+R)。

如果特征足够充分去预测的话，增加数据量就是一个很有用的方法。问问自己，给一个人类学者这么多特征，他能预测出对的结果吗？其次，在一个庞大的训练集中，是否能训练一个参数足够多的算法。在参数（特征）很多的情况下，增加数据量可以缓解过拟合现象，使得训练误差接近测试误差，使测试误差达到一个比较低的水平。

## 12（支持向量机）

### 优化目标

![image-20220315171157005](C:\Users\沙洲\AppData\Roaming\Typora\typora-user-images\image-20220315171157005.png)

回到logstic回归，我们将其代价函数进行修改，使y=1时假设函数末段直接被修改为0，而前面则使用一条接近原来导数的直线。

![image-20220315171622544](C:\Users\沙洲\AppData\Roaming\Typora\typora-user-images\image-20220315171622544.png)

就是简单修改一下，顺带一提，构建支持向量机时两个项都不需要1/m这个分数了，而且第二项前面乘的λ变成了由第一项来乘，这个也不是因为什么原因，习惯罢了，其实原理上没什么区别。![image-20220315172438600](C:\Users\沙洲\AppData\Roaming\Typora\typora-user-images\image-20220315172438600.png)

支持向量机并不会输出概率，而是只会输出0和1。如果θTX>=0则会输出1。

将代价函数这样转换可以促使模型训练时阴性时θTX往-1左边跑，阳性时往1的右边跑，使得二者能够更好地分开。这样就能得到更稳健的边界，使用更大的间距分类。

向量机在最小化代价函数时和原来的最小化不太一样。在向量机中，最小化代价函数的任务变成了在使代价函数第一项等于0的约束下，最小化第二项（正则化）。

### 数学原理--为什么分的更开了

![image-20220315205402224](C:\Users\沙洲\AppData\Roaming\Typora\typora-user-images\image-20220315205402224.png)

首先我们可以把正则化项的最小化视作使向量(θ1,θ2,θ3...)的长度相关的函数，而下面则给出了该向量受到的约束，pi指的是向量xi投影到向量θ上的距离。（第一个yi=1，第二个yi=0，ppt打错了）

![image-20220315210821963](C:\Users\沙洲\AppData\Roaming\Typora\typora-user-images\image-20220315210821963.png)

为什么会选择右边而不是左边？首先，决策边界的判定是θTx=0，所以边界x就是和θ向量正交的那条直线。因为θ0被设为0，所以边界过原点。对于左图，向量（样本）xi投影到θ向量上的距离（pi）是比较小的，导致为了满足约束条件，θ向量的长度需要变得比较大，但这又和最小化正则化项是背道而驰的，所以得到的不会是很好的结果。反观右边，向量（样本）xi投影到θ向量上的距离（pi）是比较大的，因此可以使得θ取得更小的值，最后代价函数会更小，因此我们会得到右边的结果。

### 核函数

目标：构造非线性分类器

![image-20220315221543056](C:\Users\沙洲\AppData\Roaming\Typora\typora-user-images\image-20220315221543056.png)

先换一个写法，把转换后的特征写作f。如果直接像上面这个图一样去选取特征的话计算量非常大，因为特征很多。

我们可以采用核函数的方法。首先，选取一些点（向量），每个点（向量）对应一个特征。每个点（向量）对应的特征就是：这个向量和训练集的样本的向量的相似度。![image-20220315222921971](C:\Users\沙洲\AppData\Roaming\Typora\typora-user-images\image-20220315222921971.png)

这个相似度的函数就是高斯核函数，这就是核函数的一种。还有其他用来衡量相似度的核函数。因此，如果样本离这个向量近，那么函数值就为1，如果样本离这个函数远，函数值就为0。下面的σ是一个参数，跟学习率、正则化参数差不多，可以自己手动调。显然σ越小核函数的峰越尖。

![image-20220315224151390](C:\Users\沙洲\AppData\Roaming\Typora\typora-user-images\image-20220315224151390.png)

然后我们就得到了这样的边界，>=0是标记为1。判定一个点是否属于1类，就是看这个点和这三个点的相对位置是怎么样的。

如何选择标记点呢？

我们可以直接把训练集的所有样本都作为标记点。

![image-20220315231634955](C:\Users\沙洲\AppData\Roaming\Typora\typora-user-images\image-20220315231634955.png)

在经过这样的相似变换后，我们的样本就便变成了一个m×m+1的矩阵。m个样本，每个样本对应其与所有m个样本的相似性再加上一个截距m0。

之后我们把之前的向量机的代价函数里的特征x换成现在的特征f就可以了。

![image-20220315233028127](C:\Users\沙洲\AppData\Roaming\Typora\typora-user-images\image-20220315233028127.png)

有些支持向量机正则化项会写成这样，中间的M是一个矩阵，矩阵的选取和使用的核函数有关，这样修改主要是为了提高计算效率。如果逻辑回归那里用核函数的话不是不行，但是效率太低，而支持向量机用核函数则没这个问题。

参数选择：

C：和前面的λ一样

σ：如果σ较大，则特征fi会变得更加光滑，变化缓慢，这样会增大偏差以及缩小方差，反之亦然。

### 支持向量机的实现

使用SVM软件包：liblinear、libsvm

我们只需要选择正则化参数C和核函数就行了。

使用前记得缩放数据（特征），使得大的数据不至于主导相似性。

最常用的核函数就是线性内核函数以及高斯核函数。相似函数要能满足默塞尔定理的才能用，这个定理使得软件包可以使用大类的优化方法从而迅速得到θ。其余的核函数，有如多项式核函数、卡方核函数等等。

对于分多个类别，很多SVM都已经有了函数直接做，当然你也可以做多个SVM去解决这个问题。

如果特征（10000）很多但是样本数很少（10-1000），这种时候我们一般就用逻辑回归或者线性内核函数就行。如果特征（1-1000）比较少，样本数（10-10000）大小适中，这时候高斯核函数表现得不错。如果特征（1-1000）比较少而样本数（50000+）比较多的话，这时候高斯核函数的效果就会比较好。而上面这些情况都可以使用一个良好神经网络来解决，但是缺点是速度慢。

## 13

### 无监督学习

聚类

### K-means

1、对于面前的数据，先生成n个点，n是聚类的个数，这些点被称为聚类中心。

2、遍历每一个数据，这些数据离哪个聚类中心近就把这些数据归为哪一类。

3、移动聚类中心，计算每个类每个特征的均值，以此作为这个类的新的聚类中心。

4、重复步骤2、3，如此234234不断迭代。

即使对于没有明确类别结构的数据来说，kmeans算法也能将其分为几类，有时候这样的分类也是有用的。

![image-20220320224549870](C:\Users\沙洲\AppData\Roaming\Typora\typora-user-images\image-20220320224549870.png)

这就是k-means算法的代价函数，我们的目标就是最小化这个函数（找到合适的聚类中心）。x指每个样本，μ指每个聚类中心。

对于随机初始化，初始的聚类中心直接在数据里面找就可以了。

至于如何避免不好的局部最优解，我们可以对数据进行多次随机初始化，然后选择代价函数最小的那个初始化就可以了。

### 选择聚类数量

简单的方法：画散点图，观察数据分布

进阶：肘部法则，画出代价函数的值（最小化后）随聚类个数的变化曲线图，当代价函数的值从某个k开始缓慢下降后，选取该k作为聚类个数。但有时候会得到一些比较模糊的图，不好判断具体聚几个类。

从应用入手：看看应用的时候需要几个类就聚几个类。比如说要设计三个码的T袖，那就聚三个类。

## 14

### 降维

去除冗余数据，更简洁地表示数据。还能可视化。

本质：投影

### PCA

本质：找一个低维平面，将数据投影上去，使数据到这个平面的距离的平方最小。

在进行PCA时要要先特征均值归一化和规范化（center+scale）。

如何选择降低到的维数：

![image-20220322011814580](C:\Users\沙洲\AppData\Roaming\Typora\typora-user-images\image-20220322011814580.png)

分子是每个数据到降维平面的距离的平方和的平均值，分母是数据的方差（因为已经均值化了），如果上式成立，则说明PCA后我们仍然保留了99%的方差。（只有1%损失在数据到降维平面的距离中）

### 压缩重现

乘回线性变换用的逆矩阵就行了。

### 建议

记得对于有监督学习中对训练集用就行了，不要对交叉验证集和测试集一起用。

不要想着通过PCA防止过拟合，还是要正则化。

一开始先不要pca，先直接上rawdata，得不到想要的结果后再上PCA。

## 15

### 异常检测问题

对于一个都没有异常的数据集，我们需要使用一个算法来对一个新的样本检测，看看其是否有异常。（比如检测是否有奇怪的用户）

对特征的分布概率建模，若新样本低于某阈值，则判定其异常。

### 正态分布

参数估计：对于一个给定的数据集，假设其属于某种分布，去估计其服从的分布的参数。

### 建立模型

对于每个样本，假设每个特征都是独立的，则其出现的概率P为P(x1)\*P(x2)\*...，当这个P值小于某个阈值时，可以判定其为异常点。

### 对该算法的评估

和有监督差不多，用一个测试集，里面有正常的和异常的，把算法套进去看看精确度如何。

这个算法其实和有监督比较像，只不过训练集是无标签的（都是正常的），后面的交叉验证集和测试集都差不多。

因为异常的肯定是少数所以不能直接看精度，要看precision和recall或者tp、tf、nt、nf或者F1-score。可以选择一个使F1最大的阈值来作为阈值。

### 监督vs异常检测

两者相似，怎么进行选择？

1、看阳性样本数，如果很少的话选择异常检测。

2、如果异常情况种类很多，有监督学习会比较无力，因为使用的时候可能会遇到训练集里面没有的异常，这样的话有监督就分不出来了，然而，如果是使用异常检测的话，只要是不正常的都能看出来。

3、如果正样本和负样本都很多的时候，那么使用有监督会比较好。

### 如何选择特征

1、对特征进行处理：对每个特征画数据直方图，看看其是否符合正态分布，符合的话很好，如果不符合的话就对其进行转换，比如对其log10。转换的方法很多，但是目的都是使数据看上去更符合正态分布。

2、没有人一开始就知道哪个不好，我们可以先运行算法，看看那些出错的样本的特点，看看能不能启发我们创造一些新特征或者直接减去某个特征。

3、可以通过创造特征来更好地捕获一些异常情况。

### 多元正态分布

只使用单元正态分布去进行异常检测有时候会捕获不到一些异常信息。因此可以使用多元正态分布去进行检测。![image-20220327011621773](C:\Users\沙洲\AppData\Roaming\Typora\typora-user-images\image-20220327011621773.png)

这是多元正态分布的概率公式。Σ是一个nxn的矩阵，可以说是一个超参数。多元高斯分布主要就靠这个矩阵来组合，捕获更多的信息。μ是一个nx1的矩阵，用于调整多元正态分布的中心。

其实这样就可以了，相当于估计了样本的分布：![image-20220327012741101](C:\Users\沙洲\AppData\Roaming\Typora\typora-user-images\image-20220327012741101.png)

然后直接用多元正态分布的概率去进行分析，大于阈值就判定为正常样本。

多元高斯分布可以更好地组合特征，用多个单元正态分布简单相乘只能得到多元高斯分布的一种特殊情况，十分受限。

原始模型的最大优点就是计算成本低，能适应数量巨大的特征。而且单元正态分布在样本数少的时候往往运行的也不错，但是多元正态分布则一定要样本数远大于特征数（起码要有数倍）。

多元正态分布还要求Σ是可逆矩阵，因此如果发现其不可逆的话要检查并删去两个线性相关特征的某一个（冗余特征）。

## 16

### 推荐系统

![image-20220327151121017](C:\Users\沙洲\AppData\Roaming\Typora\typora-user-images\image-20220327151121017.png)

任务：预测那些用户会给那些没看过的电影的评分，并根据评分给用户推荐电影。

### 基于内容的推荐算法

![image-20220327152914454](C:\Users\沙洲\AppData\Roaming\Typora\typora-user-images\image-20220327152914454.png)

假设对于电影有一个特征集，那么每个电影就可以用一个特征向量表示（前面加上截距x0=1）。我们可以把预测值看作线性回归问题。

![image-20220327153637822](C:\Users\沙洲\AppData\Roaming\Typora\typora-user-images\image-20220327153637822.png)

θ是通过学习得到的参数向量，其实说白了就是x1，x2是自变量，然后通过自变量得到一个分数，有些分数是已经给定了的，有些则没有，我们通过给定的去预测没有的，跟前面一样。之后就跟前面讲的线性回归一模一样了。代价函数用平方误差函数，然后梯度下降就完事了。

### 协同过滤

可以自动学习所要使用的特征。

如果用户已经告诉了我们他们的参数θ向量，那么我们就可以反其道而行之，推断特征集。其实就把θ看成特征就好了。

那么现有θ还是先有x呢？我们可以先随机出来一个θ，然后进行θ->x->θ->x->θ->x...这样不断迭代，我们就能得到一个比较好的结果了。

但是我们也不必如此麻烦，可以直接合起来做。

![image-20220327174322230](C:\Users\沙洲\AppData\Roaming\Typora\typora-user-images\image-20220327174322230.png)

我们可以直接把x和θ都视为参数，然后直接对θ和x一起进行梯度下降和正则化，然后就能一发带走啦。这里我们学习的参数不包括x0、θ0了。

从学出来的每部电影的特征向量就可以推断相似电影：距离越小越相似。

### 均值归一化

对于一个新用户，他的参数向量是00000，所以我们我们预测其结果都是0，因此没法推荐东西给他。但是，均值归一化可以改善这一点。对于我们的电影评分矩阵，我们可以将其每一行（每个电影）归一化（center）。在我们的算法最后，只要我们把均值加回来，我们仍能得到和之前一样的预测值。不过这样的话，对于一个新用户，他的每部电影预测评分就是这部电影的平均评分，这样我们就能根据这个给新用户推荐电影了。

## 17

### 学习大数据集

可以先选取较小的样本量进行测试。如果发现学习曲线J_train随样本量逐渐增大而J_cv随样本量逐渐变小，而且二者差值较大，那么说明模型存在高方差的问题，用大数据集来训练正好（过拟合）。而如果二者的差值较小，那么即使增大样本量，效果也不一定会特别好（欠拟合，特征不够）。

### 随机梯度下降

问题：当数据量太多的时候，随机梯度下降算法中的导数项计算量会很大。![image-20220328002713561](C:\Users\沙洲\AppData\Roaming\Typora\typora-user-images\image-20220328002713561.png)

这种直接对全部数据做随机梯度下降的算法叫做batch gradient descent，batch就是指批次的意思。![image-20220328003429045](C:\Users\沙洲\AppData\Roaming\Typora\typora-user-images\image-20220328003429045.png)

![image-20220328004900593](C:\Users\沙洲\AppData\Roaming\Typora\typora-user-images\image-20220328004900593.png)



如今使用的随机梯度下降算法，每次循环只考虑一个样本。

1、首先随机打乱所有数据。

2、对所有样本进行遍历，每遍历一个样本的时候，对所有参数θ进行梯度下降（只针对该样本，而不是针对所有样本然后进行求和）。

3、就这样遍历所有样本，一般1-10次，但也不会太多。

### Mini-batch梯度下降

之前我们说，进行随机梯度下降时只看对那一个样本拟合的怎么样，现在这里则是对θ进行梯度下降时一次看b个样本，b为2-100。之前我们是1个个样本遍历的，现在就变成b个样本b个样本遍历。优点是当你有一个好的向量化方式，一次使用b个样本的话，能使b个样本的总和以更向量化的方式执行，这样可以使你的b个样本中实现部分并行计算。如果有好的向量化方式，这个方法的运行速度会比随机梯度下降更快。

### 随机梯度下降收敛

之前我们提到过的确认随机梯度下降收敛的方法就是画 J_train关于迭代次数的曲线图来观察。但是我们现在数据量很大，我们不希望经常停下来计算J_train。因此我们选择了一个这种的方法，每迭代一千个样本（对θ做1k次update）后，求出这1k个样本对应的代价函数的平均值作为J_train关于迭代次数的图。通过观察这个曲线我们就能看到随机梯度下降是否收敛。一个点取的样本越多，得到的曲线就越平滑，更好看，但是花的时间久。不过有时候一次取的样本太少也可能导致噪声太多，难以观察到底有没有收敛（看起来不像在收敛）。如果曲线在上升，那可能要考虑减少学习速率或者调整算法了。有一个比较好的办法是让α随时间减小，使α=(const1/const2+iteration_number)，不过你要花时间来计算const1和const2。

### 在线学习

用途：学习数据流。

这种学习方式就是直接一个个样本地学习（就跟随机梯度下降一样）来更新自己的参数，用完就扔。这样的好处是可以适应外部因素的变化，聚焦于当下（最近的数据）。说白了就是数据太多，可以直接一个个学，学了就扔，以快速适应。和随机梯度下降一样，只不过随机梯度下降从固定的数据集里一个个地学，在线学习则从数据流里一个个学。

### 减少映射与数据并行

有时数据量太多，一台电脑跑不动。Mapreduce，这个方法可以应用于大数据集的学习中。

首先，把训练集随机平均分割为n个子集，然后用分别用n台机器去对n个子集进行学习，计算分别计算梯度下降中对应子集的导数项，然后再输出到一起加起来就能得到总的导数项了，这样的话因为直接用了n台机器，所以快很多。

能否应用该算法的关键：你的机器学习算法是否能表现为对训练集的一种求和。

即使是单机，我们也可以通过把样本发给不同的CPU进行运算来实现mapreduce。

## 18

### 照片OCR

全称：照片光学字符识别

目标：如何让计算机更好地读出图片中的文字信息。

步骤：

1、扫描图片，找出图片中的文字信息。

2、之后重点关注这些区域，对这些区域的文字进行切割，识别。

2、使用分割器对单个字符进行识别。

4、校正。

如上就是一个流程，每一步对应一个模块，相对独立，可以让不同的人分别完成。

### 滑动窗口分类器

行人识别：每个行人再图中所占的位置长宽比是差不多的。然后，我们就可以收集一些有行人和没行人的相同大小的图片用于机器学习。

之后，对于一张新的普通的图片，我们通过在原图中截取框图并将其逐渐移动来尝试捕获图中的人。搜索一次过后再使用更大但是相同比例的框图继续搜索。对于文本检测也是一样的。检测出文本后，我们需要对相邻的文本进行合并。

现在我们已经将图片中含文字的地方剪切出来了，接着，我们需要再一次进行有监督学习，学习哪里是字符的间隔地方。

### 人工数据合成

从0开始创造数据或以某种方式扩展已有的小的训练集。比如把不同的字符库的字符粘贴到一个背景图上，我们就得到了一个新样本。又或者，我们可以对原有的图进行拉伸，从原图中衍生出很多新样本。不过也要注意这些操作的合理性，不能弄出不合适的样本。比如只是加一些随机的噪音的话，那么这些新的样本的意义就很有限。添加操作时要思考操作的合理性，让自己的样本具有合理性才行。

做这项操作之前要确定你的样本具有低偏差的特征，不然加再多样本也收效不高。

问自己：如果我要获取当前数据集的10倍的数据，难度有多大？

收集数据也可以考虑众包，用别人请人标记的数据，不过有风险，因为不能保证质量。

### 上限分析

决定流程中哪个步骤是最值得花时间改进的。

对学习系统使用一个数值评价量度。

首先看第一个模块，先手动让其的准确率达到100%（直接使用真实的标签作为结果），然后接着跑剩下的模块，看看准确率提升到了多少。然后我们在第一个模块全对的基础上再使模块二的准确率达到100%，看看现在准确率又提升了多少，就这样一直做下去。我们可以看看每个模块“完美”之后对于总算法的增益是多少，然后看谁增益最大就去专注于做哪个模块。

